{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time, os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import OptionsB\n",
    "\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"user-data-dir=selenium\") \n",
    "\n",
    "###Loop through these 2 websites to get a list of book title URLs\n",
    "url = 'https://www.goodreads.com/list/show/2.The_Worst_Books_of_All_Time?page=1'\n",
    "url2 = 'https://www.goodreads.com/list/show/7.Best_Books_of_the_21st_Century?page=1'\n",
    "\n",
    "chromedriver = \"/Applications/chromedriver\" # path to the chromedriver executable\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "driver = webdriver.Chrome(chromedriver, chrome_options=chrome_options)\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "page_counter = 1\n",
    "\n",
    "book_lists = []\n",
    "page_count_list = []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_exists_by_xpath(xpath):\n",
    "    try:\n",
    "        driver.find_element_by_xpath(xpath)\n",
    "    except NoSuchElementException:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def url_gathering(expression):\n",
    "    for i in expression:\n",
    "        print(i['href'], page_counter) \n",
    "        book_lists.append((i['href']))\n",
    "        page_count_list.append(page_counter)\n",
    "\n",
    "\n",
    "soup.find_all('div', class_=\"elementList\")\n",
    "\n",
    "## Max page of the list used\n",
    "max_page = 75\n",
    "\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "url_gathering(soup.find_all('a', class_=\"bookTitle\", itemprop=\"url\"))\n",
    "while check_exists_by_xpath('/html/body/div[2]/div[3]/div[1]/div[2]/div[3]') == True:\n",
    "    if page_counter <= max_page:\n",
    "        next_button = driver.find_element_by_class_name(\"next_page\")\n",
    "        next_button.click()\n",
    "        page_counter += 1\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        url_gathering(soup.find_all('a', class_=\"bookTitle\", itemprop=\"url\"))\n",
    "        time.sleep(1)\n",
    "    else:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_worst_books = pd.DataFrame()\n",
    "df_worst_books['book_title'] = book_lists\n",
    "df_worst_books['goodreads_page_num'] = page_count_list\n",
    "#base_url = 'https://www.goodreads.com'\n",
    "\n",
    "df_worst_books.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Save output results into db\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine(\"sqlite:///regression_database.db\")\n",
    "sqlite_connection = engine.connect()\n",
    "sqlite_table = \"goodreads_worst_book_titles\"\n",
    "df_worst_books.to_sql(sqlite_table, sqlite_connection, if_exists='fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"user-data-dir=selenium\") \n",
    "\n",
    "#bmcneilgithub\n",
    "#github123\n",
    "\n",
    "url = 'https://www.goodreads.com/list/show/2.The_Worst_Books_of_All_Time?page=1'\n",
    "url2 = 'https://www.goodreads.com/list/show/7.Best_Books_of_the_21st_Century?page=1'\n",
    "\n",
    "chromedriver = \"/Applications/chromedriver\" # path to the chromedriver executable\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "driver = webdriver.Chrome(chromedriver, chrome_options=chrome_options)\n",
    "driver.get(url2)\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "page_counter = 1\n",
    "\n",
    "book_lists = []\n",
    "page_count_list = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_exists_by_xpath(xpath):\n",
    "    try:\n",
    "        driver.find_element_by_xpath(xpath)\n",
    "    except NoSuchElementException:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def url_gathering(expression):\n",
    "    for i in expression:\n",
    "        print(i['href'], page_counter) \n",
    "        book_lists.append((i['href']))\n",
    "        page_count_list.append(page_counter)\n",
    "\n",
    "\n",
    "soup.find_all('div', class_=\"elementList\")\n",
    "#url_gathering(soup.find_all('div', class_=\"elementList\"))        \n",
    "\n",
    "max_page = 75\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "url_gathering(soup.find_all('a', class_=\"bookTitle\", itemprop=\"url\"))\n",
    "while check_exists_by_xpath('/html/body/div[2]/div[3]/div[1]/div[2]/div[3]') == True:\n",
    "    if page_counter <= max_page:\n",
    "        next_button = driver.find_element_by_class_name(\"next_page\")\n",
    "        next_button.click()\n",
    "        page_counter += 1\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        url_gathering(soup.find_all('a', class_=\"bookTitle\", itemprop=\"url\"))\n",
    "        time.sleep(1)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_books = pd.DataFrame()\n",
    "df_best_books['book_title'] = book_lists\n",
    "df_best_books['goodreads_page_num'] = page_count_list\n",
    "#base_url = 'https://www.goodreads.com'\n",
    "\n",
    "df_best_books.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlite_table = \"goodreads_best_book_titles\"\n",
    "df_best_books.to_sql(sqlite_table, sqlite_connection, if_exists='fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
